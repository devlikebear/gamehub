/**
 * AI ìŒì•… ìƒì„±ê¸° (Gemini Lyria RealTime)
 */

import { ApiKeyManager } from '@/lib/sprite/ApiKeyManager';
import { UsageTracker } from '@/lib/sprite/UsageTracker';
import type { MusicParams, MusicGenerationResult } from './types';
import { buildBGMPrompt, buildSFXPrompt, validatePrompt } from './musicPrompts';

export class MusicGenerator {
  private static readonly API_BASE_URL = 'https://generativelanguage.googleapis.com/v1beta';
  private static readonly MODEL_NAME = 'models/lyria-realtime-exp';

  /**
   * ìŒì•… í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  private static buildPrompt(params: MusicParams): string {
    if (params.type === 'bgm') {
      return buildBGMPrompt(
        params.genre!,
        params.mood!,
        params.length!,
        params.prompt
      );
    } else {
      return buildSFXPrompt(params.prompt);
    }
  }

  /**
   * ìŒì•… ìƒì„± (Gemini Lyria API)
   */
  static async generate(params: MusicParams): Promise<MusicGenerationResult> {
    const startTime = Date.now();

    try {
      // 1. API í‚¤ ë¡œë“œ
      const apiKey = ApiKeyManager.loadApiKey();
      if (!apiKey) {
        return {
          success: false,
          error: 'API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
        };
      }

      // 2. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ê²€ì¦
      const prompt = this.buildPrompt(params);
      const validation = validatePrompt(prompt);
      if (!validation.valid) {
        return { success: false, error: validation.error };
      }

      console.log('ğŸµ ìŒì•… ìƒì„± ì‹œì‘:', { type: params.type, prompt });

      // 3. Gemini Lyria API í˜¸ì¶œ
      const response = await fetch(
        `${this.API_BASE_URL}/${this.MODEL_NAME}:generateContent?key=${apiKey}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [
              {
                parts: [{ text: prompt }],
              },
            ],
            generationConfig: {
              temperature: 0.8,
              topK: 40,
              topP: 0.95,
            },
          }),
        }
      );

      if (!response.ok) {
        const errorData = await response.json();
        console.error('Gemini API ì˜¤ë¥˜:', errorData);
        return {
          success: false,
          error: `API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`,
        };
      }

      // 4. ì‘ë‹µ íŒŒì‹±
      const data = await response.json();
      console.log('âœ… API ì‘ë‹µ ìˆ˜ì‹ :', data);

      if (!data.candidates || data.candidates.length === 0) {
        return {
          success: false,
          error: 'ìŒì•… ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.',
        };
      }

      const content = data.candidates[0].content;
      if (!content || !content.parts || content.parts.length === 0) {
        return {
          success: false,
          error: 'ìƒì„±ëœ ìŒì•… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
        };
      }

      // 5. ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ (Base64)
      const audioPart = content.parts.find(
        (part: { inlineData?: { data: string; mimeType: string } }) => part.inlineData
      );
      if (!audioPart || !audioPart.inlineData) {
        return {
          success: false,
          error: 'ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        };
      }

      const audioData = audioPart.inlineData.data;
      const mimeType = audioPart.inlineData.mimeType || 'audio/wav';
      const format = mimeType.includes('mp3') ? 'mp3' : 'wav';

      // 6. Data URL ìƒì„±
      const audioUrl = `data:${mimeType};base64,${audioData}`;

      // 7. ë°”ì´ë„ˆë¦¬ ë°ì´í„° ë³€í™˜
      const binaryData = Uint8Array.from(atob(audioData), (c) => c.charCodeAt(0));

      // 8. ì‚¬ìš©ëŸ‰ ê¸°ë¡
      const duration = params.type === 'bgm' ? params.length || 30 : 2;
      const estimatedCost = params.type === 'bgm' ? 0.05 : 0.02; // BGM: $0.05, SFX: $0.02

      UsageTracker.recordUsage(params.type, estimatedCost, false);

      const elapsedTime = ((Date.now() - startTime) / 1000).toFixed(1);
      console.log(`âœ… ìŒì•… ìƒì„± ì™„ë£Œ (${elapsedTime}ì´ˆ)`);

      return {
        success: true,
        audioUrl,
        audioData: binaryData,
        duration,
        format,
        metadata: {
          prompt,
          model: this.MODEL_NAME,
          timestamp: Date.now(),
          cost: estimatedCost,
        },
      };
    } catch (error) {
      console.error('ìŒì•… ìƒì„± ì‹¤íŒ¨:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      };
    }
  }

  /**
   * ì˜¤ë””ì˜¤ í›„ì²˜ë¦¬ (í˜ì´ë“œ ì¸/ì•„ì›ƒ, ë£¨í”„ í¬ì¸íŠ¸, ë…¸ë©€ë¼ì´ì œì´ì…˜)
   */
  static async postProcess(
    audioData: Uint8Array,
    options: {
      fadeIn?: number; // ì´ˆ ë‹¨ìœ„
      fadeOut?: number; // ì´ˆ ë‹¨ìœ„
      normalize?: boolean;
      loopEnabled?: boolean;
    }
  ): Promise<Blob> {
    try {
      // AudioContext ìƒì„±
      const audioContext = new AudioContext();

      // ArrayBufferë¡œ ë³€í™˜ (ë³µì‚¬)
      const buffer = new ArrayBuffer(audioData.byteLength);
      const view = new Uint8Array(buffer);
      view.set(audioData);

      // ì˜¤ë””ì˜¤ ë””ì½”ë”©
      const audioBuffer = await audioContext.decodeAudioData(buffer);

      // í˜ì´ë“œ ì¸/ì•„ì›ƒ ì ìš©
      if (options.fadeIn || options.fadeOut) {
        const channelData = audioBuffer.getChannelData(0);
        const sampleRate = audioBuffer.sampleRate;

        // í˜ì´ë“œ ì¸
        if (options.fadeIn) {
          const fadeInSamples = Math.floor(options.fadeIn * sampleRate);
          for (let i = 0; i < fadeInSamples && i < channelData.length; i++) {
            channelData[i] *= i / fadeInSamples;
          }
        }

        // í˜ì´ë“œ ì•„ì›ƒ
        if (options.fadeOut) {
          const fadeOutSamples = Math.floor(options.fadeOut * sampleRate);
          const startSample = channelData.length - fadeOutSamples;
          for (let i = 0; i < fadeOutSamples && startSample + i < channelData.length; i++) {
            channelData[startSample + i] *= (fadeOutSamples - i) / fadeOutSamples;
          }
        }
      }

      // ë…¸ë©€ë¼ì´ì œì´ì…˜
      if (options.normalize) {
        const channelData = audioBuffer.getChannelData(0);
        let maxAmplitude = 0;

        for (let i = 0; i < channelData.length; i++) {
          const absValue = Math.abs(channelData[i]);
          if (absValue > maxAmplitude) {
            maxAmplitude = absValue;
          }
        }

        if (maxAmplitude > 0 && maxAmplitude < 1) {
          const gain = 0.95 / maxAmplitude;
          for (let i = 0; i < channelData.length; i++) {
            channelData[i] *= gain;
          }
        }
      }

      // WAV ë³€í™˜
      const wavBlob = await this.audioBufferToWav(audioBuffer);

      audioContext.close();
      return wavBlob;
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ í›„ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      // í›„ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜ (ArrayBufferë¡œ ë³µì‚¬)
      const fallbackBuffer = new ArrayBuffer(audioData.byteLength);
      const fallbackView = new Uint8Array(fallbackBuffer);
      fallbackView.set(audioData);
      return new Blob([fallbackBuffer], { type: 'audio/wav' });
    }
  }

  /**
   * AudioBufferë¥¼ WAV Blobìœ¼ë¡œ ë³€í™˜
   */
  private static async audioBufferToWav(buffer: AudioBuffer): Promise<Blob> {
    const numChannels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    const length = buffer.length * numChannels * 2;
    const arrayBuffer = new ArrayBuffer(44 + length);
    const view = new DataView(arrayBuffer);

    // WAV í—¤ë”
    this.writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + length, true);
    this.writeString(view, 8, 'WAVE');
    this.writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * 2, true);
    view.setUint16(32, numChannels * 2, true);
    view.setUint16(34, 16, true);
    this.writeString(view, 36, 'data');
    view.setUint32(40, length, true);

    // PCM ë°ì´í„°
    let offset = 44;
    for (let i = 0; i < buffer.length; i++) {
      for (let ch = 0; ch < numChannels; ch++) {
        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(ch)[i]));
        view.setInt16(offset, sample * 0x7fff, true);
        offset += 2;
      }
    }

    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }

  /**
   * DataViewì— ë¬¸ìì—´ ì“°ê¸°
   */
  private static writeString(view: DataView, offset: number, string: string) {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }
}
